\hypertarget{algorithmic-differentiation-and-the-newton-method}{%
\section{10. Algorithmic differentiation and the Newton
method}\label{algorithmic-differentiation-and-the-newton-method}}

\begin{frame}{Last time}
\protect\hypertarget{last-time}{}

\begin{itemize}
\item
  Linear regression and intro to machine learning
\item
  Derivatives
\item
  Algorithmic differentiation
\end{itemize}

\end{frame}

\begin{frame}{Today}
\protect\hypertarget{today}{}

\begin{itemize}
\item
  Tips from Problem Set 3
\item
  Review of algorithmic differentiation
\item
  Newton method for finding roots
\item
  Higher dimensions
\end{itemize}

\end{frame}

\hypertarget{tips-from-problem-set-3}{%
\section{Tips from Problem Set 3}\label{tips-from-problem-set-3}}

\begin{frame}[fragile]{Style}
\protect\hypertarget{style}{}

\begin{itemize}
\item
  Spaces around \texttt{=} and operators, and after comma
\item
  Blank lines separating conceptually different blocks of code
\item
  Function names: \emph{no} capitals; types: each word capitalised
\item
  Use names of enums instead of converting to \texttt{Int}
\item
  Do not use abbreviated names like \texttt{sta} or \texttt{stt} for
  \texttt{status}
\item
  e.g.~\texttt{possible\_locations} instead of \texttt{locpos}
\end{itemize}

\end{frame}

\begin{frame}[fragile]{Style II}
\protect\hypertarget{style-ii}{}

\begin{itemize}
\item
  If calculating a Boolean condition, \emph{don't} do e.g.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{if}\NormalTok{ a < }\FloatTok{0}
    \KeywordTok{return}\NormalTok{ true}
\KeywordTok{else}
    \KeywordTok{return}\NormalTok{ false}
\KeywordTok{end}
\end{Highlighting}
\end{Shaded}
\item
  Just do \texttt{return\ a\ \textless{}\ 0}
\item
  Don't use ``magic numbers'' like
  \texttt{dynamics!(L,\ 0.70,\ 0.01,\ new\_list\_agents\_2,\ 100,\ 100)}
\item
  Give those \texttt{0.70} and \texttt{100} a \emph{name}
\end{itemize}

\end{frame}

\begin{frame}[fragile]{Julia tips}
\protect\hypertarget{julia-tips}{}

\begin{itemize}
\item
  Don't need \texttt{Pkg.add} each time -- once only to install the
  package
\item
  Do need \texttt{using} each time
\item
  If have numerical values, try to avoid \texttt{if} looping over all
  the different values
\item
  Subtypes of \texttt{AbstractWalker2D} are not necessarily mutable
\end{itemize}

\end{frame}

\begin{frame}[fragile]{PS3 Q.6}
\protect\hypertarget{ps3-q.6}{}

\begin{itemize}
\item
  \texttt{initialize} function is ``irrelevant'' to computational
  complexity
\item
  Run once so cost ``amortised'' if run simulation for a long time
\item
  Expensive part is looping over all walkers to look for collisions
\item
  So store locations of walkers in a \texttt{Dict} or \texttt{Matrix}
\item
  \texttt{Matrix} is twice as fast (?)
\item
  But need to keep this data structure updated as walkers move
\end{itemize}

\end{frame}

\begin{frame}{Algorithmic differentiation}
\protect\hypertarget{algorithmic-differentiation}{}

\begin{itemize}
\item
  Recall: Want to calculate derivatives exactly and automatically
\item
  By following rules for combining derivatives
\item
  E.g. \((f \cdot g)'(a) = f(a) g'(a) + f'(a) g(a)\)
\item
  For each function \(f\) need pair \((f(a), f'(a))\)
\end{itemize}

\end{frame}

\begin{frame}[fragile]{Implementation}
\protect\hypertarget{implementation}{}

\begin{itemize}
\item
  Defined new ``dual number'' type:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{struct Dual}
\NormalTok{    value::}\DataTypeTok{Float64}
\NormalTok{    deriv::}\DataTypeTok{Float64}
\KeywordTok{end}

\NormalTok{f = Dual(}\FloatTok{3}\NormalTok{, }\FloatTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}
\item
  \texttt{f} is an object representing a function \(f\) with
  \((f(a), f'(a)) = (3, 4)\)
\item
  Usual \emph{not} to explicitly represent evaluation point \(a\) in
  dual numbers
\end{itemize}

\end{frame}

\begin{frame}[fragile]{Arithmetic}
\protect\hypertarget{arithmetic}{}

\begin{itemize}
\item
  Define getters

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{val(f::Dual) = f.value}
\NormalTok{der(f::Dual) = f.deriv}
\end{Highlighting}
\end{Shaded}
\item
  And arithmetic operations on that type:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{import}\NormalTok{ Base: *}

\NormalTok{*(f::Dual, g::Dual) = Dual(val(f) * val(g),}
\NormalTok{                           val(f) * der(g), der(f) * val(g))}
\end{Highlighting}
\end{Shaded}
\end{itemize}

\end{frame}

\begin{frame}[fragile]{Meaning of dual number}
\protect\hypertarget{meaning-of-dual-number}{}

\begin{itemize}
\item
  Approximation of function near given point \(a\)
\item
  \texttt{Dual(c,\ d)} is function that looks like \(c + \epsilon d\)
\item
  \(\epsilon = x - a\) is distance from \(a\)
\item
  Represents function \(f\) with \(f(a) = c\) and \(f'(a) = d\)
\item
  As the pair \((f(a), f'(a))\)
\end{itemize}

\end{frame}

\begin{frame}{Interpretation of dual number}
\protect\hypertarget{interpretation-of-dual-number}{}

\begin{itemize}
\item
  ``Where you are and how fast you're moving''
\item
  Tangent line
\item
  Polynomial of order 1 (affine function)
\end{itemize}

\end{frame}

\begin{frame}[fragile]{Applying functions to dual numbers}
\protect\hypertarget{applying-functions-to-dual-numbers}{}

\begin{itemize}
\item
  Suppose \(g(x)\) is a given function
\item
  What happens if apply \(g\) to a dual number \(c + d \epsilon\)?
\item
  \(g(c + d\epsilon) = g(c) + \epsilon \cdot g'(c) \cdot d\)
\item
  In particular,
\end{itemize}

\[g(a + \epsilon) = g(a) + \epsilon g'(a)\]

\begin{itemize}
\item
  So pass in \(a + \epsilon\), i.e.~\texttt{Dual(a,\ 1)}, to calculate
  derivative
\item
  Derivative is coefficient of \(\epsilon\)
\end{itemize}

\end{frame}

\begin{frame}[fragile]{Functions of dual numbers}
\protect\hypertarget{functions-of-dual-numbers}{}

\begin{itemize}
\item
  Suppose \texttt{f\ =\ Dual(c,\ d)} represents function \(f(x)\) near
  \(a\)
\item
  Then e.g.~\texttt{sin(f)} should represent \(g(x) = \sin(f(x))\) near
  \(a\)
\item
  Value \(g(a) = \sin(f(a))\)
\item
  Derivative \(g'(a) = \sin'(f(a)) \cdot f'(a)\) by chain rule
\item
  Code:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Base.sin(f::Dual) = Dual(sin(val(f)),}
\NormalTok{                         cos(val(f)) * der(f))}
\end{Highlighting}
\end{Shaded}
\end{itemize}

\end{frame}

\begin{frame}{Chain rule}
\protect\hypertarget{chain-rule}{}

\begin{itemize}
\item
  Suppose \(g(x)\) is a given function
\item
  What happens if apply \(g\) to a dual number \(c + d \epsilon\)
  representing \(f\)?
\item
  Have \(c = f(a)\) and \(d = f'(a)\)
\item
  So \(g(c + d\epsilon) = g(f(a)) + \epsilon \, g'(f(a)) \cdot f'(a)\)
\item
  Chain rule is \emph{automatically encoded} in derivative of \(g\)
\end{itemize}

\end{frame}

\hypertarget{finding-roots-using-the-newton-method}{%
\section{Finding roots using the Newton
method}\label{finding-roots-using-the-newton-method}}

\begin{frame}{Roots}
\protect\hypertarget{roots}{}

\begin{itemize}
\item
  Often want to solve \(f(x) = 0\) for \textbf{nonlinear} function \(f\)
\item
  \textbf{Root}: Solution \(x^*\) where \(f(x^*) = 0\) (or
  \textbf{zero})
\item
  General nonlinear equation \(f(x) = 0\) cannot be solved exactly
\item
  E.g. polynomials of degree \(\ge 5\)
\item
  But we still want to find roots (numerically)!
\item
  How could we do this?
\end{itemize}

\end{frame}

\begin{frame}{Iterative methods}
\protect\hypertarget{iterative-methods}{}

\begin{itemize}
\item
  Idea: Look for a discrete-time recurrence \(x_{n+1} = \alpha(x_n)\)
\item
  Start from initial guess \(x_0\)
\item
  Want sequence \(x_0\), \(x_1\), \(\ldots\) with \(x_n \to x^{*}\) as
  \(n \to \infty\).
\item
  Many possible choices of algorithms \(\alpha\)
\item
  We will look at \textbf{Newton method} -- uses derivative \(f'\)
\item
  How?
\end{itemize}

\end{frame}

\begin{frame}{Newton(--Raphson) method}
\protect\hypertarget{newtonraphson-method}{}

\begin{itemize}
\item
  Draw picture
\item
  Start from \((x_0, f(x_0))\)
\item
  Follow tangent line down
\item
  Intersect it with \(x\)-axis to give new guess \(x_1\)
\item
  Repeat
\end{itemize}

\end{frame}

\begin{frame}{Derivation of Newton method}
\protect\hypertarget{derivation-of-newton-method}{}

\begin{itemize}
\item
  Want to find \(x_1 = x_0 + \delta \quad\) (defines \(\delta\))
\item
  Solve \(f(x_1) = f(x_0 + \delta) = 0\)
\item
  Still nonlinear so \emph{linearize}:
\item
  Taylor expand to linear order in \(\delta\):
\end{itemize}

\[f(x_0 + \delta) \simeq f(x_0) + \delta f'(x_0)\]

\end{frame}

\begin{frame}{}
\protect\hypertarget{section}{}

\begin{itemize}
\item
  Have \[f(x_1) = f(x_0 + \delta) \simeq f(x_0) + \delta f'(x_0)\]
\item
  So replace \(f(x_1) = 0\) with approximation
\end{itemize}

\[f(x_0) + \delta f'(x_0) \simeq 0\]

\begin{itemize}
\item
  Gives \(x_1 = x_0 - \frac{f(x_0)}{f'(x_0)}\)
\item
  In general get recurrence
\end{itemize}

\[\boxed{x_{n+1} = x_n - \frac{f(x_n)}{f'(x_n)}}\]

\end{frame}

\begin{frame}[fragile]{Implementation}
\protect\hypertarget{implementation-1}{}

\begin{itemize}
\item
  Implement:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{function}\NormalTok{ newton(f, f′, x0, N=}\FloatTok{20}\NormalTok{)}
\NormalTok{    x = x0}
\NormalTok{    xs = [x0]}

    \KeywordTok{for}\NormalTok{ i }\KeywordTok{in} \FloatTok{1}\NormalTok{:N}
\NormalTok{        x = x - f(x) / f′(x)}
\NormalTok{        push!(xs, x)}
    \KeywordTok{end}

    \KeywordTok{return}\NormalTok{ xs}
\KeywordTok{end}
\end{Highlighting}
\end{Shaded}
\end{itemize}

\end{frame}

\begin{frame}{Convergence}
\protect\hypertarget{convergence}{}

\begin{itemize}
\item
  Newton method \emph{does not always converge}
\item
  But when it does, it converges ``fast'' -- how fast?
\item
  Is there a difference if use numerical or exact derivative?
\item
  Numerical derivatives give something like
  \href{https://en.wikipedia.org/wiki/Secant_method}{secant method}
\item
  Newton is ``better'' but each step may be more expensive
\end{itemize}

\end{frame}

\begin{frame}{Optimization}
\protect\hypertarget{optimization}{}

\begin{itemize}
\item
  Can use Newton or related methods to find minima
\item
  How?
\item
  What does this need?
\end{itemize}

\end{frame}

\begin{frame}{Optimization II}
\protect\hypertarget{optimization-ii}{}

\begin{itemize}
\item
  Solve \(f'(x) = 0\)
\item
  So need derivatives of the derivative, i.e.~\emph{2nd derivatives}
\item
  Can also calculate automatically
\end{itemize}

\end{frame}

\begin{frame}{Higher dimensions}
\protect\hypertarget{higher-dimensions}{}

\begin{itemize}
\item
  What happens for higher-dimensional functions
\item
  E.g. \(f(x, y) = x^2 + y^2 - 1\)
\item
  Generalise approach from 1D
\item
  Pass in dual numbers with \emph{same} \(\epsilon\):
\item
  Set \(x = a + c\epsilon\) and \(y = b + d \epsilon\)
\item
  Calculate \[f(a + c\epsilon, b + d \epsilon)\]
\end{itemize}

\end{frame}

\begin{frame}{Partial derivatives}
\protect\hypertarget{partial-derivatives}{}

\begin{itemize}
\item
  Calculate \[f(a + c\epsilon, b + d \epsilon)\]
\item
  Expand: \[f(a, b) + c \epsilon \frac{\partial f}{\partial x}(a, b)
                + d \epsilon \frac{\partial f}{\partial y}(a, b)
                + O(\epsilon^2)\]
\item
  Coefficient of \(\epsilon\) is

  \[c \frac{\partial f}{\partial x}(a, b) + d  \frac{\partial f}{\partial y}(a, b)\]
\item
  Derivatives evaluated at \((a, b)\)
\item
  What is this derivative?
\end{itemize}

\end{frame}

\begin{frame}{Directional derivative}
\protect\hypertarget{directional-derivative}{}

\begin{itemize}
\item
  Have
  \[c \frac{\partial f}{\partial x} + d  \frac{\partial f}{\partial y}\]
\item
  This is \[\nabla f(a, b) \cdot \mathbf{v}\]
\item
  Where \(\mathbf{v} = (c, d)\)
\item
  \textbf{Directional derivative} in direction \(\mathbf{v}\)
\item
  How calculate this? How calculate partial derivatives?
\end{itemize}

\end{frame}

\begin{frame}[fragile]{Calculating directional derivatives}
\protect\hypertarget{calculating-directional-derivatives}{}

\begin{itemize}
\item
  \texttt{f(Dual(a,\ v₁),\ Dual(b,\ v₂)} calculates
  \(\nabla f(a, b) \cdot \mathbf{v}\)!
\item
  \(\mathbf{v} = (1, 0)\) gives \(\partial f / \partial x\)
\item
  \(\mathbf{v} = (0, 1)\) gives \(\partial f / \partial y\)
\end{itemize}

\end{frame}

\begin{frame}{Jacobian}
\protect\hypertarget{jacobian}{}

\begin{itemize}
\item
  For \(f: \mathbb{R}^2 \to \mathbb{R}^2\), have \(f = (f_1, f_2)\) with

  \[f_i(\mathbf{a} + \epsilon \mathbf{v}) = f_i(\mathbf{a}) + \epsilon \nabla f_i(\mathbf{a}) \cdot \mathbf{v}\]
\item
  So
  \[f(\mathbf{a} + \epsilon \mathbf{v}) = f(\mathbf{a}) + \epsilon \, Df(\mathbf{a}) \cdot \mathbf{v}\]
\item
  \(Df(\mathbf{a})\) is \textbf{Jacobian matrix} -- matrix of partial
  derivatives \(\frac{\partial f_i}{\partial x_j}\)
\item
  Coefficient of \(\epsilon\) is Jacobian--vector product
\end{itemize}

\end{frame}

\begin{frame}{Newton in higher dimensions}
\protect\hypertarget{newton-in-higher-dimensions}{}

\begin{itemize}
\item
  Generalise argument for Newton method from 1D to higher dimensions:
\item
  Look for root of \(f(\mathbf{x}) = \mathbf{0}\).
\item
  Initial guess \(\mathbf{x}_0\)
\item
  Let \(\mathbf{x}_1 = \mathbf{x}_0 + \pmb{\delta}\); want to find
  \(\pmb{\delta}\)
\end{itemize}

\end{frame}

\begin{frame}{}
\protect\hypertarget{section-1}{}

\begin{itemize}
\item
  Want \(f(\mathbf{x}_1) = f(\mathbf{x}_0 + \pmb{\delta}) = 0\)
\item
  Approximate:
\end{itemize}

\[f(\mathbf{x}_0) + \mathsf{J} \cdot \pmb{\delta} \simeq \mathbf{0}\]

\begin{itemize}
\item
  Where \(\mathsf{J} := Df(\mathbf{a})\)
\item
  So need to solve \emph{system of linear equations}
\end{itemize}

\[ \mathsf{J} \cdot \pmb{\delta} = -f(\mathbf{a}) \]

\end{frame}

\begin{frame}[fragile]{Linear algebra in Julia}
\protect\hypertarget{linear-algebra-in-julia}{}

\begin{itemize}
\item
  Given matrix \(\mathsf{A}\) and vector \(\mathbf{b}\)
\item
  Solve \(\mathsf{A} \cdot \mathbf{x} = \mathbf{b}\) for vector
  \(\mathbf{x}\):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x = A \textbackslash{} b}
\end{Highlighting}
\end{Shaded}
\item
  \texttt{\textbackslash{}} is a kind of ``division''
\end{itemize}

\end{frame}

\begin{frame}{Review}
\protect\hypertarget{review}{}

\begin{itemize}
\item
  Automatic differentiation
\item
  Derivatives of higher-dimensional functions
\item
  Application to root finding: Newton method
\end{itemize}

\end{frame}
