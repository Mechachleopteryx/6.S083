# 6.S083 - Introduction to Computational Thinking (Common Ground)

## Fall 2019

Welcome to 6.S083! This is an introductory course on Computational Thinking, using the Julia programming language.

### Professors
David P. Sanders ([sandersd@mit.edu](mailto:sandersd@mit.edu)) & Alan Edelman

### Lectures
MW 1 - 2.30, room 34-301

### Office hours
TR 11 - 1, Julia lab, floor 7 of Stata Center (turn left from Gates building elevator)

### Evaluation

*   5 problem sets, 20% each
*   No final exam

Problem sets consist of coding and answering questions and will be submitted online.

### Syllabus


<table>
  <tr>
   <td>
<ol>

Lecture 1<br>
Introduction to Julia

</ol>
   </td>
   <td>October 21
<p>
- PS 0 out
   </td>
   <td>- Abstractions: Functions & types
<p>
- Interpreters & compilers
   </td>
  </tr>
  <tr>
   <td>
<ol>

Lecture 2
<br>
Discrete-time iterative dynamics


</ol>
   </td>
   <td>October 23
<p>
- PS 0 due
<p>
- PS 1 out
   </td>
   <td>- Vectors as containers
<p>
- Higher-order functions
<p>
- Visualization
<p>
- Interactivity
<p>
- Markdown
   </td>
  </tr>
  <tr>
   <td>
<ol>

Lecture 3
<br>
Randomness and probability

</ol>
   </td>
   <td>October 28
   </td>
   <td>- Dictionaries as containers
<p>
- Counting
<p>
- Sampling
<p>
- Git and Github
   </td>
  </tr>
  <tr>
   <td>
<ol>

Lecture 4
<br>
Random walks

</ol>
   </td>
   <td>October 30
<p>
- PS 1 due
<p>
- PS 2 out
   </td>
   <td>- Building up programs
<p>
- Array comprehensions
<p>
- Broadcasting
<p>
- Vectors of vectors vs matrices
<p>
- Type stability and performance
   </td>
  </tr>
  <tr>
   <td>
<ol>

Lecture 5 <br>
Monte Carlo

</ol>
   </td>
   <td>November 4
   </td>
   <td>- Simulation
<p>
- Rejection sampling
<p>
- Iterators
<p>
- Individual-based models
   </td>
  </tr>
  <tr>
   <td>
<ol>

Lecture 6 <br>
Continuous probability distributions

</ol>
   </td>
   <td>November 6
<p>
- PS 2 due
<p>
- PS 3 out
   </td>
   <td>- Histograms
<p>
- Standard error of the mean
   </td>
  </tr>
  <tr>
   <td>
    No class (Veteranâ€™s Day)
   </td>
   <td>November 11
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>
<ol>


Lecture 7 <br>
Algorithmic differentiation

</ol>
   </td>
   <td>November 13
   </td>
   <td>- Abstractions: Types
<p>
- Abstract interpretation
<p>
- Multiple dispatch  \
- Unit tests
   </td>
  </tr>
  <tr>
   <td>
<ol>

Lecture 8 <br>
Applications of differentiation

</li>
</ol>
   </td>
   <td>November 18
<p>
- PS 3 due
<p>
- PS 4 out
   </td>
   <td>- Higher-order functions
<p>
- Callable types
   </td>
  </tr>
  <tr>
   <td>
<ol>

Lecture 9 <br>
Graphs and algorithms

</ol>
   </td>
   <td>November 20
   </td>
   <td>- Data structures for graphs
<p>
- Search algorithms
   </td>
  </tr>
  <tr>
   <td>
<ol>

Lecture 10 <br>
Data and linear regression

</ol>
   </td>
   <td>November 25
<p>
- PS 4 due
   </td>
   <td>- Data file formats
<p>
- Reading and writing data
<p>
- Data frames
<p>
- Stochastic gradient descent
   </td>
  </tr>
  <tr>
   <td>
    Class cancelled (Thanksgiving travel) \

   </td>
   <td>November 27
<p>
- PS 5 out
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>
<ol>

Lecture 11 <br>
Introduction to machine learning

</ol>
   </td>
   <td>December 2
   </td>
   <td>- Train/test splitting
   </td>
  </tr>
  <tr>
   <td>
<ol>

Lecture 12 <br>
Unsupervised learning: Clustering

</ol>
   </td>
   <td>December 4
   </td>
   <td>- K-means algorithm
   </td>
  </tr>
  <tr>
   <td>
<ol>

Lecture 13 <br>
Supervised learning: Neural networks
</li>
</ol>
   </td>
   <td>December 9
<p>
- PS 5 due
   </td>
   <td>- Stochastic gradient descent
<p>
- GPUs
   </td>
  </tr>
  <tr>
   <td>
<ol>

Lecture 14 <br>
Interval arithmetic methods
</ol>
   </td>
   <td>December 11
   </td>
   <td>Floating-point arithmetic
